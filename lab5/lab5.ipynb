{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 5:\n",
    "    1. Download Alice in Wonderland by Lewis Carroll from Project Gutenberg's website http://www.gutenberg.org/files/11/11-0.txt\n",
    "    2. Perform any necessary preprocessing on the text, including converting to lower case, removing stop words, numbers / non-alphabetic characters, lemmatization.\n",
    "    3. Find Top 10 most important (for example, in terms of TF-IDF metric) words from each chapter in the text (not \"Alice\"); how would you name each chapter according to the identified tokens?\n",
    "    4. Find the Top 10 most used verbs in sentences with Alice. What does Alice do most often?\n",
    "    5. *(not necessary) Find Top 100 most used verbs in sentences with Alice. Get word vectors using a pre-trained word2vec model and visualize them. Compare the words using embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import urllib.request  # the lib that handles the url stuff\n",
    "import spacy\n",
    "\n",
    "alice_handler = urllib.request.urlopen(\"http://www.gutenberg.org/files/11/11-0.txt\")\n",
    "alice_text = alice_handler.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define english utf nlp vocab\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Basic preprocessing. Remove copyright, tokenize, lemmatize, remove stop words\n",
    "\n",
    "end = \"*** END OF THIS PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\"\n",
    "start = \"*** START OF THIS PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\"\n",
    "\n",
    "alice_text = alice_text[alice_text.index(start) + len(start):]\n",
    "alice_text = alice_text[:alice_text.index(end) - len(end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alice_text_nlp = nlp(alice_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_text(doc):\n",
    "    Nouns = []\n",
    "    Noun_set = []\n",
    "    trimmed_noun_set = []\n",
    "    removing_duplicates = []\n",
    "    arr = []\n",
    "    vocab = []\n",
    "    vocab_dict = {}\n",
    "\n",
    "    nlp.vocab[\"ALICE\"].is_stop = True\n",
    "\n",
    "    doc = nlp(doc.lower())\n",
    "\n",
    "    for possible_nouns in doc:\n",
    "        if possible_nouns.pos_ in [\"NOUN\",\"PROPN\"] and not possible_nouns.is_stop:\n",
    "            Nouns.append(possible_nouns)\n",
    "\n",
    "\n",
    "    for i in Nouns:\n",
    "        Noun_set.append([i])\n",
    "\n",
    "    for i in Noun_set:\n",
    "            trimmed_noun_set.append([i])\n",
    "\n",
    "    for word in trimmed_noun_set:\n",
    "        if word not in removing_duplicates:\n",
    "            removing_duplicates.append(word)\n",
    "\n",
    "    for word in Noun_set:\n",
    "        string = ''\n",
    "        for j in word:\n",
    "            string+= str(j)+ \" \"\n",
    "        vocab.append(string.strip())\n",
    "\n",
    "    for word in vocab:\n",
    "        if word == \"_\":\n",
    "            continue\n",
    "        if word not in vocab_dict:\n",
    "            vocab_dict[word]= 0\n",
    "        else:\n",
    "            vocab_dict[word]+=1\n",
    "    arr = vocab_dict.keys()\n",
    "    return vocab_dict , arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def computeTF(wordDict,bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict\n",
    "\n",
    "\n",
    "def computeIDF(doclist):\n",
    "    count = 0\n",
    "    idfDict = {}\n",
    "    for element in doclist:\n",
    "        for j in element:\n",
    "            count+=1\n",
    "    N = count\n",
    "\n",
    "    # count number of usages of word w in doc\n",
    "    idfDict = dict.fromkeys(doclist[0].keys(),0)\n",
    "\n",
    "    for doc in doclist:\n",
    "        for word,val in doc.items():\n",
    "            if val>0:\n",
    "                idfDict[word]+= 1\n",
    "\n",
    "    # divide N by denominator above\n",
    "    for word,val in idfDict.items():\n",
    "        if val == 0:\n",
    "            idfDict[word] = 0.0\n",
    "        else:\n",
    "            idfDict[word] = math.log(N / float(val))\n",
    "\n",
    "    return idfDict\n",
    "\n",
    "def computeTfidf(tf,idf):\n",
    "    tfidf = {}\n",
    "    sorted_list = []\n",
    "    for word , val in tf.items():\n",
    "        tfidf[word] = val * idf[word]\n",
    "\n",
    "    ranking_list  = sorted(tfidf.items(),reverse=True, key = lambda kv:(kv[1], kv[0]))[:10]\n",
    "    for i, _ in ranking_list:\n",
    "        sorted_list.append(i)\n",
    "\n",
    "    return sorted_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split text into chapters\n",
    "import re\n",
    "chapters = re.split('CHAPTER *', alice_text)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Find most import words using tf-idf metric. We will use pairs(pronoun+noun, verb+noun etc..) in order to come up with meaningfull chapter names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words (a.k.a. chapter name) 0 ['rabbit', 'i.', 'hole']\n",
      "Top 10 words (a.k.a. chapter name) 1 ['tears', 'pool']\n",
      "Top 10 words (a.k.a. chapter name) 2 ['tale', 'race', 'caucus']\n",
      "Top 10 words (a.k.a. chapter name) 3 ['rabbit', 'bill']\n",
      "Top 10 words (a.k.a. chapter name) 4 ['advice']\n",
      "Top 10 words (a.k.a. chapter name) 5 ['vi', 'pig', 'pepper']\n",
      "Top 10 words (a.k.a. chapter name) 6 ['tea', 'party']\n",
      "Top 10 words (a.k.a. chapter name) 7 ['viii', 'queen', 'ground', 'croquet']\n",
      "Top 10 words (a.k.a. chapter name) 8 ['turtle', 'story']\n",
      "Top 10 words (a.k.a. chapter name) 9 ['lobster']\n",
      "Top 10 words (a.k.a. chapter name) 10 ['tarts']\n",
      "Top 10 words (a.k.a. chapter name) 11 ['xii', 'evidence', 'alice']\n",
      "Top 10 words (a.k.a. chapter name) 12 ['alice', 'way', 'time', 'rabbit', 'door', 'key', 'use', 'things', 'table', 'people']\n",
      "Top 10 words (a.k.a. chapter name) 13 ['alice', 'mouse', 'way', 'pool', 'feet', 'things', 'cats', 'tears', 'time', 'voice']\n",
      "Top 10 words (a.k.a. chapter name) 14 ['mouse', 'alice', 'dodo', 'thing', 'race', 'lory', 'course', 'question', 'prizes', 'birds']\n",
      "Top 10 words (a.k.a. chapter name) 15 ['alice', 'rabbit', 'bill', 'window', 'thing', 'voice', 'room', 'puppy', 'moment', 'gloves']\n",
      "Top 10 words (a.k.a. chapter name) 16 ['alice', 'caterpillar', 'pigeon', 'youth', 'size', 'bit', 'tone', 'time', 'serpent', 'mouth']\n",
      "Top 10 words (a.k.a. chapter name) 17 ['alice', 'cat', 'footman', 'duchess', 'baby', 'way', 'pig', 'door', 'cook', 'thing']\n",
      "Top 10 words (a.k.a. chapter name) 18 ['alice', 'hatter', 'dormouse', 'march', 'hare', 'time', 'tea', 'thing', 'twinkle', 'treacle']\n",
      "Top 10 words (a.k.a. chapter name) 19 ['queen', 'alice', 'king', 'head', 'cat', 'soldiers', 'gardeners', 'game', 'voice', 'rabbit']\n",
      "Top 10 words (a.k.a. chapter name) 20 ['alice', 'turtle', 'gryphon', 'duchess', 'queen', 'day', 'tone', 'thing', 'school', 'moral']\n",
      "Top 10 words (a.k.a. chapter name) 21 ['gryphon', 'turtle', 'alice', 'dance', 'soup', 'voice', 'whiting', 'sea', 'soo', 'oop']\n",
      "Top 10 words (a.k.a. chapter name) 22 ['king', 'hatter', 'court', 'alice', 'dormouse', 'witness', 'queen', 'rabbit', 'jury', 'voice']\n",
      "Top 10 words (a.k.a. chapter name) 23 ['king', 'alice', 'jury', 'queen', 'rabbit', 'sister', 'head', 'voice', 'dream', 'verses']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for i,chapter in enumerate(chapters):\n",
    "    vocab_dict , arr = prepare_text(chapter)\n",
    "    tf = computeTF(vocab_dict,arr)\n",
    "    idf = computeIDF([vocab_dict])\n",
    "    tfidf = computeTfidf(tf,idf)\n",
    "    print(f\"Top 10 words (a.k.a. chapter name) {i} {tfidf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_alice_verbs(doc):\n",
    "    verbs = []\n",
    "\n",
    "    doc = nlp(doc.upper())\n",
    "\n",
    "\n",
    "    for possible_nouns in doc:\n",
    "        #print(possible_nouns.lemma_)\n",
    "        if possible_nouns.lemma_.lower()==\"alice\":\n",
    "            if possible_nouns.head.pos_ == \"VERB\" and possible_nouns.head.text.lower() != 'alice':\n",
    "\n",
    "                cand = [possible_nouns.text, possible_nouns.head.text]\n",
    "                verbs.append(cand[1])\n",
    "    return set(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_count_verbs = {}\n",
    "for chapter in chapters:\n",
    "    cur_keys = find_alice_verbs(chapter)\n",
    "\n",
    "    for key in cur_keys:\n",
    "        if key in total_count_verbs:\n",
    "            total_count_verbs[key]+=1\n",
    "        else:\n",
    "            total_count_verbs[key]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SAID': 12,\n",
       " 'THOUGHT': 6,\n",
       " 'BEGAN': 5,\n",
       " 'WENT': 5,\n",
       " 'HAD': 3,\n",
       " 'THINK': 3,\n",
       " 'CRIED': 3,\n",
       " 'BEEN': 3,\n",
       " 'BE': 3,\n",
       " 'TURNING': 3,\n",
       " 'WAITED': 3,\n",
       " 'WAS': 3,\n",
       " 'SEE': 3,\n",
       " 'VENTURED': 2,\n",
       " 'HEARD': 2,\n",
       " 'LOOKING': 2,\n",
       " 'TELL': 2,\n",
       " 'BEGINNING': 2,\n",
       " 'LIKE': 2,\n",
       " 'SEEN': 2,\n",
       " '’S': 2,\n",
       " 'MOVED': 2,\n",
       " 'GOT': 2,\n",
       " 'LOOKED': 2,\n",
       " 'ADVISE': 1,\n",
       " 'STARTED': 1,\n",
       " 'SHUTTING': 1,\n",
       " 'TOOK': 1,\n",
       " 'OUGHT': 1,\n",
       " 'UNDERSTAND': 1,\n",
       " 'CALLED': 1,\n",
       " 'SEEMED': 1,\n",
       " 'POINTING': 1,\n",
       " 'KEPT': 1,\n",
       " 'ALLOW': 1,\n",
       " 'WHISPERS': 1,\n",
       " 'HAVE': 1,\n",
       " 'CAN’T': 1,\n",
       " 'CROUCHED': 1,\n",
       " 'SAW': 1,\n",
       " 'KEEP': 1,\n",
       " 'DID': 1,\n",
       " 'SUPPOSE': 1,\n",
       " 'CONSIDERED': 1,\n",
       " 'WISH': 1,\n",
       " 'TRIED': 1,\n",
       " 'COMING': 1,\n",
       " 'KNOW': 1,\n",
       " 'SHOUTED': 1,\n",
       " 'GAVE': 1,\n",
       " 'CAME': 1,\n",
       " 'FOUND': 1,\n",
       " 'HEAR': 1,\n",
       " 'WANTED': 1,\n",
       " 'FEEL': 1,\n",
       " 'SPEAK': 1,\n",
       " 'LEAVING': 1,\n",
       " 'PANTED': 1,\n",
       " 'TAKING': 1,\n",
       " 'THANK': 1,\n",
       " 'ASKED': 1,\n",
       " 'DARE': 1,\n",
       " 'MADE': 1,\n",
       " 'IMAGINE': 1,\n",
       " 'LET': 1,\n",
       " 'WAKE': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most used verbs\n",
    "dict(sorted(total_count_verbs.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
