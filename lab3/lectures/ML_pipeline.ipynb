{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-wYJpaYojUw"
      },
      "source": [
        "# Titanic passengers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWDAp1NIonvz"
      },
      "source": [
        "#### Goal: will a person survive or not?\n",
        "\n",
        "#### Metrics: accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4USZfyWo0YN"
      },
      "source": [
        "\n",
        "# import libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-rtkyDbo4E3"
      },
      "source": [
        "# read data and get train info\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/test.csv')\n",
        "train.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULE9f7C6Z5Qr"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be3gMoTqqCp2"
      },
      "source": [
        "# get statisitcs  \n",
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cYgXCGiqILm"
      },
      "source": [
        "# show the overall survival rate \n",
        "print('Overall Survival Rate:', round(train['Survived'].mean(), 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucqgtRHnrskL"
      },
      "source": [
        "## Data cleaning and feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JGZm3diq5Cr"
      },
      "source": [
        "# get_dummies function\n",
        "def dummies(col,train,test):\n",
        "    train_dum = pd.get_dummies(train[col])\n",
        "    test_dum = pd.get_dummies(test[col])\n",
        "    train = pd.concat([train, train_dum], axis=1)\n",
        "    test = pd.concat([test,test_dum],axis=1)\n",
        "    train.drop(col,axis=1,inplace=True)\n",
        "    test.drop(col,axis=1,inplace=True)\n",
        "    return train, test\n",
        "\n",
        "# delete the useless cols\n",
        "dropping = ['PassengerId', 'Name', 'Ticket']\n",
        "train.drop(dropping,axis=1, inplace=True)\n",
        "test.drop(dropping,axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz8_4YDSr5N2"
      },
      "source": [
        "# pclass\n",
        "# ensure no NA contained\n",
        "print(train.Pclass.value_counts(dropna=False))\n",
        "sns.factorplot('Pclass', 'Survived',data=train, order=[1,2,3])\n",
        "# according to the graph, we found there are huge differences between\n",
        "# each pclass group. keep the ft\n",
        "train, test = dummies('Pclass', train, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsZwN7Eor_XW"
      },
      "source": [
        "# sex\n",
        "print(train.Sex.value_counts(dropna=False))\n",
        "sns.factorplot('Sex','Survived', data=train)\n",
        "# female survival rate is way better than the male\n",
        "train, test = dummies('Sex', train, test)\n",
        "\n",
        "#train.drop('male',axis=1,inplace=True)\n",
        "#test.drop('male',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ0xZ1yXZ5Qu"
      },
      "source": [
        "#age \n",
        "#dealing the missing data\n",
        "nan_num = train['Age'].isnull().sum()\n",
        "print(nan_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb8Q9Up3Z5Qu"
      },
      "source": [
        "# there are 177 missing value, fill with random int\n",
        "age_mean = train['Age'].mean()\n",
        "age_std = train['Age'].std()\n",
        "filling = np.random.randint(age_mean-age_std, age_mean+age_std, size=nan_num)\n",
        "train['Age'][train['Age'].isnull()==True] = filling\n",
        "nan_num = train['Age'].isnull().sum()\n",
        "print(nan_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qnTaMCIZ5Qv"
      },
      "source": [
        "# dealing the missing val in test\n",
        "nan_num = test['Age'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBPYK96ZZ5Qv"
      },
      "source": [
        "# 86 null\n",
        "age_mean = test['Age'].mean()\n",
        "age_std = test['Age'].std()\n",
        "filling = np.random.randint(age_mean-age_std,age_mean+age_std,size=nan_num)\n",
        "test['Age'][test['Age'].isnull()==True]=filling\n",
        "nan_num = test['Age'].isnull().sum()\n",
        "print(nan_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ideFMKGkZ5Qv"
      },
      "source": [
        "#family\n",
        "print(train['SibSp'].value_counts(dropna=False))\n",
        "print(train['Parch'].value_counts(dropna=False))\n",
        "\n",
        "sns.factorplot('SibSp','Survived',data=train,size=5)\n",
        "sns.factorplot('Parch','Survived',data=train,size=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2FYX94EsHQ3"
      },
      "source": [
        "'''through the plot, we suggest that with more family member, \n",
        "the survival rate will drop, we can create the new col\n",
        "add up the parch and sibsp to check our theory''' \n",
        "\n",
        "train['family'] = train['SibSp'] + train['Parch']\n",
        "test['family'] = test['SibSp'] + test['Parch']\n",
        "sns.factorplot('family','Survived',data=train,size=5)\n",
        "\n",
        "train.drop(['SibSp','Parch'],axis=1,inplace=True)\n",
        "test.drop(['SibSp','Parch'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWA01_B9Z5Qw"
      },
      "source": [
        "# fare\n",
        "print(train.Fare.isnull().sum())\n",
        "print(test.Fare.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DcDNFRCsNiT"
      },
      "source": [
        "sns.factorplot('Survived','Fare',data=train,size=5)\n",
        "test['Fare'].fillna(test['Fare'].median(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es2oweKhZ5Qw"
      },
      "source": [
        "#Cabin\n",
        "# checking missing val\n",
        "# 687 out of 891 are missing, drop this col\n",
        "train.Cabin.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nraF5tLsR-W"
      },
      "source": [
        "train.drop('Cabin',axis=1,inplace=True)\n",
        "test.drop('Cabin',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RJvtgpKZ5Qx"
      },
      "source": [
        "#Embark\n",
        "print(train.Embarked.isnull().sum())\n",
        "# 2 missing value\n",
        "train.Embarked.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOPQqoqCsUzc"
      },
      "source": [
        "# fill the majority val,'s', into missing val col\n",
        "train['Embarked'].fillna('S',inplace=True)\n",
        "\n",
        "sns.factorplot('Embarked','Survived',data=train,size=6)\n",
        "train,test = dummies('Embarked',train,test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHId8fXhsYv3"
      },
      "source": [
        "## Model and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHkKg0OFsW6T"
      },
      "source": [
        "# import machine learning libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X=train.drop('Survived',axis=1)\n",
        "y=train['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
        "\n",
        "\n",
        "# check classification scores of logistic regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "\n",
        "print('Train/Test split results:')\n",
        "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIPmWggqw2VB"
      },
      "source": [
        "## CrossValidation\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7VIcJ3ktGUV"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import datasets\r\n",
        "from sklearn import svm\r\n",
        "\r\n",
        "X, y = datasets.load_iris(return_X_y=True)\r\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIxl0ueb99A"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    X, y, test_size=0.4, random_state=0)\r\n",
        "\r\n",
        "print(X_train.shape, y_train.shape)\r\n",
        "print(X_test.shape, y_test.shape)\r\n",
        "\r\n",
        "\r\n",
        "clf = svm.SVC(kernel='linear').fit(X_train, y_train)\r\n",
        "clf.score(X_test, y_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QGNGgupcDMN"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\r\n",
        "clf = svm.SVC(kernel='linear', random_state=42)\r\n",
        "scores = cross_val_score(clf, X, y, cv=15)\r\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-sagvjKcLli"
      },
      "source": [
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBfIPZjZcTIR"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "scores = cross_val_score(\r\n",
        "    clf, X, y, cv=5, scoring='recall_macro')\r\n",
        "scores\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSiAfAQYcfXQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}